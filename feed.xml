<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://nikolaibobenko.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://nikolaibobenko.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-08-02T09:46:15+00:00</updated><id>https://nikolaibobenko.github.io/feed.xml</id><title type="html">Nikolai Bobenko</title><subtitle>Randomness and Learning </subtitle><entry><title type="html">Dimer Phenomenology</title><link href="https://nikolaibobenko.github.io/blog/2024/Dimer-Phenomenology/" rel="alternate" type="text/html" title="Dimer Phenomenology"/><published>2024-07-01T00:00:00+00:00</published><updated>2024-07-01T00:00:00+00:00</updated><id>https://nikolaibobenko.github.io/blog/2024/Dimer-Phenomenology</id><content type="html" xml:base="https://nikolaibobenko.github.io/blog/2024/Dimer-Phenomenology/"><![CDATA[<p>I want to write an informal arcticle discussion the dimer model and phenomena occuring in it.</p>]]></content><author><name></name></author><category term="research"/><category term="dimers"/><summary type="html"><![CDATA[I want to write an informal arcticle discussion the dimer model and phenomena occuring in it.]]></summary></entry><entry><title type="html">Arbitrary Style Transfer in Real Time!</title><link href="https://nikolaibobenko.github.io/blog/2020/arbitrary-style-transfer-real-time/" rel="alternate" type="text/html" title="Arbitrary Style Transfer in Real Time!"/><published>2020-10-01T00:00:00+00:00</published><updated>2020-10-01T00:00:00+00:00</updated><id>https://nikolaibobenko.github.io/blog/2020/arbitrary-style-transfer-real-time</id><content type="html" xml:base="https://nikolaibobenko.github.io/blog/2020/arbitrary-style-transfer-real-time/"><![CDATA[<p>Here is my presentation of the style transfer paper. This method allows to train a single network to transfer arbitrary styles between arbitrary images and is very fast at generation time.</p> <p>Notable is the definition of style. It is simply defined as the statistics (In this case first and second moment) of the middle layers of some pretrained image recognition network. It is not obvious that this should be the correct definition of style but these results indicate that it is a useful one. Furthermore now there is work building on this idea. Most notably NVidia’s <a href="https://arxiv.org/abs/1812.04948">StyleGAN</a> uses these style transfer layers to allow for human face generation on a level that has been out of reach before.</p> <figure> <iframe src="https://www.youtube.com/embed/jDadRuMSTHQ" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"/> </figure>]]></content><author><name></name></author><category term="papersexplained"/><category term="papersexplained"/><summary type="html"><![CDATA[A walk through the style transfer paper]]></summary></entry><entry><title type="html">Your GAN is secretly an Energy Based Model</title><link href="https://nikolaibobenko.github.io/blog/2020/GAN-secretly-EBM/" rel="alternate" type="text/html" title="Your GAN is secretly an Energy Based Model"/><published>2020-09-22T00:00:00+00:00</published><updated>2020-09-22T00:00:00+00:00</updated><id>https://nikolaibobenko.github.io/blog/2020/GAN-secretly-EBM</id><content type="html" xml:base="https://nikolaibobenko.github.io/blog/2020/GAN-secretly-EBM/"><![CDATA[<p>I am pleased to announce my explainer channel <a href="https://www.youtube.com/channel/UCzEl7XeZz-wE2LHVyJs2AXw">PapersExplained</a>. I will use it for quick explanation videos of current research literature that is accessibly explainable to an interested audience with some maths background but no presumption of being experts in the field. I will focus on papers that include some unique theoretical perspectives as opposed to mostly experimental results.</p> <p>With that said please enjoy “Your GAN is secretly an Energy Based Model”. This simple new approach derives a representation of standard GANs as energy based models and allows one to use the information from both the descriminator and generator to improve generation performance.</p> <figure> <iframe src="https://www.youtube.com/embed/cKe_Uy3XU1g" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"/> </figure>]]></content><author><name></name></author><category term="papersexplained"/><category term="papersexplained"/><summary type="html"><![CDATA[An energy-based method for sampling from GANs.]]></summary></entry></feed>